{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据读取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv\n",
    "# head()\n",
    "# shape\n",
    "# columns\n",
    "# index\n",
    "# dtype\n",
    "\n",
    "# pd.read_excel\n",
    "# pd.read_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据结构**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataFrame:二维数组\n",
    "* Series:一维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list\n",
    "s = pd.Series([1, 2, 3], index = [1, 2, 3])\n",
    "\n",
    "#dict\n",
    "#获取多个值df[[a,b]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  b  c\n",
       "0 NaN  2  3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict,key是columns\n",
    "df = pd.DataFrame({\n",
    "    'a': [np.nan, 2, 3],\n",
    "    'b': [2, 3, 4],\n",
    "    'c': [3, 4, 5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b  c  e  f  g\n",
       "0  NaN  2  3  1  2  3\n",
       "1  2.0  3  4  2  3  4\n",
       "2  3.0  4  5  3  4  5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'e': [1, 2, 3],\n",
    "    'f': [2, 3, 4],\n",
    "    'g': [3, 4, 5]\n",
    "})\n",
    "\n",
    "pd.concat([df, df2], ignore_index = False, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 一列或者一行是series\n",
    "* 多行多列是dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  1  2\n",
      "1  2  3\n",
      "2  3  4\n"
     ]
    }
   ],
   "source": [
    "#列\n",
    "#print(df[['a', 'b']])\n",
    "\n",
    "#行 输入是index名字，index变成列名\n",
    "#print(df.loc[])\n",
    "#print(df.loc[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据查询**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df.loc\n",
    "* df.iloc\n",
    "* df.where\n",
    "* df.query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.使用单个label值查询数据\n",
    "\n",
    "2.使用值列表批量查询\n",
    "\n",
    "3.使用数值区间进行范围查询\n",
    "\n",
    "4.使用条件表达式查询\n",
    "\n",
    "5.调用函数查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定索引, inplace真表示在当前df更改，假表示返回一个更改后的df\n",
    "df.set_index('a', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、使用单个label值查询数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 得到单个值\n",
    "# df.loc['2018-01-03', 'bWendu']\n",
    "# # 得到一个Series\n",
    "# df.loc['2018-01-03', ['bWendu', 'yWendu']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、使用值列表批量查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 得到Series\n",
    "# df.loc[['2018-01-03','2018-01-04','2018-01-05'], 'bWendu']\n",
    "\n",
    "# # 得到DataFrame\n",
    "# df.loc[['2018-01-03','2018-01-04','2018-01-05'], ['bWendu', 'yWendu']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、使用数值区间进行范围查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 行和列都按区间查询\n",
    "# df.loc['2018-01-03':'2018-01-05', 'bWendu':'fengxiang']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、使用条件表达式查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "Name: b, dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df[\"yWendu\"]<-10, :]\n",
    "# df.loc[df['b'] <= 3, :]\n",
    "# df['b'] <= 3\n",
    "\n",
    "\n",
    "# df.loc[(df[\"bWendu\"]<=30) & (df[\"yWendu\"]>=15) & (df[\"tianqi\"]=='晴') & (df[\"aqiLevel\"]==1), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、调用函数查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接写lambda表达式\n",
    "# df.loc[lambda df : (df[\"bWendu\"]<=30) & (df[\"yWendu\"]>=15), :]\n",
    "\n",
    "# 编写自己的函数，查询9月份，空气质量好的数据\n",
    "# def query_my_data(df):\n",
    "#     return df.index.str.startswith(\"2018-09\") & (df[\"aqiLevel\"]==1)\n",
    "    \n",
    "# df.loc[query_my_data, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **新增数据列**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.直接赋值\n",
    "\n",
    "2.df.apply方法\n",
    "\n",
    "3.df.assign方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、直接赋值的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 替换掉温度的后缀℃\n",
    "# df.loc[:, \"bWendu\"] = df[\"bWendu\"].str.replace(\"℃\", \"\").astype('int32')\n",
    "# df.loc[:, \"yWendu\"] = df[\"yWendu\"].str.replace(\"℃\", \"\").astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、df.apply方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects passed to the function are Series objects whose index is either the DataFrame’s index (axis=0) or the DataFrame’s columns (axis=1). 1表示每一行都要沿着列做这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wendu_type(x):\n",
    "    if x[\"bWendu\"] > 33:\n",
    "        return '高温'\n",
    "    if x[\"yWendu\"] < -10:\n",
    "        return '低温'\n",
    "    return '常温'\n",
    "\n",
    "# 注意需要设置axis==1，这是series的index是columns\n",
    "df.loc[:, \"wendu_type\"] = df.apply(get_wendu_type, axis=1)\n",
    "\n",
    "# 查看每种类型以及个数\n",
    "df[\"wendu_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、df.assign方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时添加多个列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以同时添加多个新的列\n",
    "df.assign(\n",
    "    yWendu_huashi = lambda x : x[\"yWendu\"] * 9 / 5 + 32,\n",
    "    # 摄氏度转华氏度\n",
    "    bWendu_huashi = lambda x : x[\"bWendu\"] * 9 / 5 + 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、按条件选择分组分别赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先创建空列（这是第一种创建新列的方法）\n",
    "# df['wencha_type'] = ''\n",
    "\n",
    "# df.loc[df[\"bWendu\"]-df[\"yWendu\"]>10, \"wencha_type\"] = \"温差大\"\n",
    "\n",
    "# df.loc[df[\"bWendu\"]-df[\"yWendu\"]<=10, \"wencha_type\"] = \"温差正常\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据统计函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、汇总类统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         b    c\n",
       "count  3.0  3.0\n",
       "mean   3.0  4.0\n",
       "std    1.0  1.0\n",
       "min    2.0  3.0\n",
       "25%    2.5  3.5\n",
       "50%    3.0  4.0\n",
       "75%    3.5  4.5\n",
       "max    4.0  5.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一下子提取所有数字列统计结果\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、唯一去重和按值计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #一般不用于数值列，而是枚举、分类列\n",
    "# df[\"fengxiang\"].unique()\n",
    "\n",
    "# #按值计数\n",
    "# df[\"fengxiang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、相关系数和协方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #协方差：衡量同向反向程度，如果协方差为正，说明X，Y同向变化，协方差越大说明同向程度越高；如果协方差为负，说明X，Y反向运动，协方差越小说明反向程度越高。\n",
    "# # 协方差矩阵：\n",
    "# df.cov()\n",
    "\n",
    "# #相关系数：衡量相似度程度，当他们的相关系数为1时，说明两个变量变化时的正向相似度最大，当相关系数为－1时，说明两个变量变化的反向相似度最大\n",
    "# # 相关系数矩阵\n",
    "# df.corr()\n",
    "# # 单独查看空气质量和最高温度的相关系数\n",
    "# df[\"aqi\"].corr(df[\"bWendu\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **缺失值处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* isnull和notnull：检测是否是空值，可用于df和series\n",
    "* dropna：丢弃、删除缺失值\n",
    " * axis : 删除行还是列，{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    " * how : 如果等于any则任何值为空都删除，如果等于all则所有值都为空才删除\n",
    " * inplace : 如果为True则修改当前df，否则返回新的df\n",
    "* fillna：填充空值\n",
    " * value：用于填充的值，可以是单个值，或者字典（key是列名，value是值）\n",
    " * method : 等于ffill使用前一个不为空的值填充forword fill；等于bfill使用后一个不为空的值填充backword fill\n",
    " * axis : 按行还是列填充，{0 or ‘index’, 1 or ‘columns’}\n",
    " * inplace : 如果为True则修改当前df，否则返回新的df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'studf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-567b5d85621c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstudf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#返回True/False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstudf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"分数\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 筛选没有空分数的所有行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'studf' is not defined"
     ]
    }
   ],
   "source": [
    "# studf.isnull() #返回True/False\n",
    "# studf[\"分数\"].notnull()\n",
    "\n",
    "\n",
    "# # 筛选没有空分数的所有行\n",
    "# studf.loc[studf[\"分数\"].notnull(), :]\n",
    "\n",
    "# #删除掉全是空值的列\n",
    "# studf.dropna(axis=\"columns\", how='all', inplace=True)\n",
    "# #删除掉全是空值的行\n",
    "# studf.dropna(axis=\"index\", how='all', inplace=True)\n",
    "\n",
    "# studf.fillna({\"分数\":0})\n",
    "# # 等同于\n",
    "# studf.loc[:, '分数'] = studf['分数'].fillna(0)\n",
    "# # 使用前面的有效值填充，用ffill：forward fill\n",
    "# studf.loc[:, '姓名'] = studf['姓名'].fillna(method=\"ffill\")\n",
    "\n",
    "\n",
    "# studf.to_excel(\"./datas/student_excel/student_excel_clean.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据排序**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series的排序：\n",
    "\n",
    "Series.sort_values(ascending=True, inplace=False)\n",
    "\n",
    "参数说明：\n",
    "* ascending：默认为True升序排序，为False降序排序\n",
    "* inplace：是否修改原始Series\n",
    "\n",
    "DataFrame的排序：\n",
    "\n",
    "DataFrame.sort_values(by, ascending=True, inplace=False)\n",
    "\n",
    "参数说明：\n",
    "* by：字符串或者List，单列排序或者多列排序\n",
    "* ascending：bool或者List\n",
    "* inplace：是否修改原始DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame的排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单列排序，所有行都会改变\n",
    "df.sort_values(by=\"aqi\")\n",
    "\n",
    "#多列排序\n",
    "# 按空气质量等级、最高温度排序，默认升序\n",
    "df.sort_values(by=[\"aqiLevel\", \"bWendu\"]) #先比较先出现的columns\n",
    "# 分别指定升序和降序\n",
    "df.sort_values(by=[\"aqiLevel\", \"bWendu\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **字符串处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "Name: s1, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先获取Series的str属性，在属性上调用函数\n",
    "#智能在字符串列\n",
    "#DF没有，用的是Series的\n",
    "df_str = pd.DataFrame({\n",
    "   \"s1\": [\"fdsd\", \"asdf1\"],\n",
    "   \"s2\": [\"Hello\", \"Myword1\"] \n",
    "})\n",
    "df_str[\"s1\"].str.contains(\"1\") #replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Axis问题**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0：index，1：columns，axis是啥，啥动起来，别的不动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Index用途**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b  c\n",
       "1  2.0  3  4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() #出现多少条\n",
    "\n",
    "#查询数据\n",
    "df.loc[df.index==1, :]\n",
    "\n",
    "#提升查询效率\n",
    "#唯一最快，其次有序，所以可以先排序\n",
    "df_sorted = df_shuffle.sort_index()\n",
    "\n",
    "#index自动对齐数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merge**\n",
    "按key值关联到一个表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge的语法：\n",
    "\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
    "\n",
    "* left，right：要merge的dataframe或者有name的Series\n",
    "* how：join类型，'left', 'right', 'outer', 'inner'\n",
    "* on：join的key，left和right都需要有这个key\n",
    "* left_on：left的df或者series的key\n",
    "* right_on：right的df或者seires的key\n",
    "* left_index，right_index：使用index而不是普通的column做join\n",
    "* suffixes：两个元素的后缀，如果列有重名，自动添加后缀，默认是('_x', '_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **concat**\n",
    "多个合并\n",
    "* concat语法：pandas.concat(objs, axis=0, join='outer', ignore_index=False)\n",
    "* objs：一个列表，内容可以是DataFrame或者Series，可以混合\n",
    "* axis：默认是0代表按行合并，如果等于1代表按列合并\n",
    "* join：合并的时候索引的对齐方式，默认是outer join，也可以是inner join\n",
    "* ignore_index：是否忽略掉原来的数据索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #使用join=inner过滤掉不匹配的列\n",
    "# pd.concat([df1,df2], ignore_index=True, join=\"inner\")\n",
    "\n",
    "# #添加多列Series\n",
    "# pd.concat([df1,s1,s2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append语法：DataFrame.append(other, ignore_index=False)\n",
    "\n",
    "append只有按行合并，没有按列合并，相当于concat按行的简写形式\n",
    "* other：单个dataframe、series、dict，或者列表\n",
    "* ignore_index：是否忽略掉原来的数据索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **批量拆分与合并Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work_dir=\"./\"\n",
    "# split_dir=f\"{work_dir}/splits\"\n",
    "\n",
    "# import os\n",
    "# if not os.path.exists(splits_dir):\n",
    "#     os.mkdir(splits_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_raw_count = df_source.shape[0]\n",
    "\n",
    "# #大excel拆分成多个excel\n",
    "# #使用iloc，将大拆分成小\n",
    "# #然后to_excel\n",
    "\n",
    "\n",
    "# # 每个人的任务数目\n",
    "# split_size = total_row_count // len(user_names)\n",
    "# if total_row_count % len(user_names) != 0:\n",
    "#     split_size += 1\n",
    "\n",
    "# split_size\n",
    "\n",
    "# df_subs = []\n",
    "# for idx, user_name in enumerate(user_names):\n",
    "#     # iloc的开始索引\n",
    "#     begin = idx*split_size\n",
    "#     # iloc的结束索引\n",
    "#     end = begin+split_size\n",
    "#     # 实现df按照iloc拆分\n",
    "#     df_sub = df_source.iloc[begin:end]\n",
    "#     # 将每个子df存入列表\n",
    "#     df_subs.append((idx, user_name, df_sub))\n",
    "    \n",
    "# for idx, user_name, df_sub in df_subs:\n",
    "#     file_name = f\"{splits_dir}/crazyant_blog_articles_{idx}_{user_name}.xlsx\"\n",
    "#     df_sub.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 遍历文件夹，得到要合并的Excel文件列表\n",
    "# # 分别读取到dataframe，给每个df添加一列用于标记来源\n",
    "# # 使用pd.concat进行df批量合并\n",
    "# # 将合并后的dataframe输出到excel\n",
    "\n",
    "\n",
    "# import os\n",
    "# excel_names = []\n",
    "# for excel_name in os.listdir(splits_dir):\n",
    "#     excel_names.append(excel_name)\n",
    "# excel_names\n",
    "\n",
    "# df_list = []\n",
    "\n",
    "# for excel_name in excel_names:\n",
    "#     # 读取每个excel到df\n",
    "#     excel_path = f\"{splits_dir}/{excel_name}\"\n",
    "#     df_split = pd.read_excel(excel_path)\n",
    "#     # 得到username\n",
    "#     username = excel_name.replace(\"crazyant_blog_articles_\", \"\").replace(\".xlsx\", \"\")[2:]\n",
    "#     print(excel_name, username)\n",
    "#     # 给每个df添加1列，即用户名字\n",
    "#     df_split[\"username\"] = username\n",
    "    \n",
    "#     df_list.append(df_split)\n",
    "\n",
    "\n",
    "# df_merged = pd.concat(df_list)\n",
    "# df_merged.to_excel(f\"{work_dir}/crazyant_blog_articles_merged.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-527773171e20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#数据统计\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#查看单列的结果数据统计\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#不同列使用不同的聚合函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#数据统计\n",
    "df.groupby(['a', 'b'], as_index=False).agg([np.sum, np.mean])\n",
    "#查看单列的结果数据统计\n",
    "df.groupby('a', as_index=False).agg([np.sum, np.mean])['b']\n",
    "#不同列使用不同的聚合函数\n",
    "df.groupby('a').agg({\"b\":np.sum, \"c\":np.mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **分层索引MultiIndex**\n",
    "分层索引：在一个轴向上拥有多个索引层级，可以表达更高维度数据的形式；\n",
    "\n",
    "可以更方便的进行数据筛选，如果有序则性能更好；\n",
    "\n",
    "groupby等操作的结果，如果是多KEY，结果是分层索引，需要会使用\n",
    "\n",
    "一般不需要自己创建分层索引(MultiIndex有构造函数但一般不用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DataFrame的多层索引MultiIndex\n",
    "# stocks.set_index(['公司', '日期'], inplace=True)\n",
    "# stocks.sort_index(inplace=True)\n",
    "# #元组(key1,key2)代表筛选多层索引，其中key1是索引第一级，key2是第二级，比如key1=JD, key2=2019-10-02\n",
    "# #列表[key1,key2]代表同一层的多个KEY，其中key1和key2是并列的同级索引，比如key1=JD, key2=BIDU\n",
    "# stocks.loc['BIDU']\n",
    "# stocks.loc[('BIDU', '2019-10-02'), :]\n",
    "# # slice(None)代表筛选这一索引的所有内容\n",
    "# stocks.loc[(slice(None), ['2019-10-02', '2019-10-03']), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **map、apply、applymap**\n",
    "数据转换函数对比：map、apply、applymap：\n",
    "* map：只用于Series，实现每个值->值的映射；\n",
    "* apply：用于Series实现每个值的处理，用于Dataframe实现某个轴的Series的处理；\n",
    "* applymap：只能用于DataFrame，用于处理该DataFrame的每个元素；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #方法1：Series.map(dict)\n",
    "# stocks[\"公司中文1\"] = stocks[\"公司\"].str.lower().map(dict_company_names)\n",
    "# #方法2：Series.map(function)\n",
    "# stocks[\"公司中文2\"] = stocks[\"公司\"].map(lambda x : dict_company_names[x.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-bbfdda5ff693>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Series.apply(function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m stocks[\"公司中文3\"] = stocks[\"公司\"].apply(\n\u001b[0m\u001b[0;32m      3\u001b[0m     lambda x : dict_company_names[x.lower()])\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#DataFrame.apply(function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m stocks[\"公司中文4\"] = stocks.apply(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stocks' is not defined"
     ]
    }
   ],
   "source": [
    "# #Series.apply(function)\n",
    "# stocks[\"公司中文3\"] = stocks[\"公司\"].apply(\n",
    "#     lambda x : dict_company_names[x.lower()])\n",
    "# #DataFrame.apply(function)\n",
    "# stocks[\"公司中文4\"] = stocks.apply(\n",
    "#     lambda x : dict_company_names[x[\"公司\"].lower()], \n",
    "#     axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applymap用于DataFrame所有值的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df.applymap(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group&apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getWenduTopN(df, topn):\n",
    "#     \"\"\"\n",
    "#     这里的df，是每个月份分组group的df\n",
    "#     \"\"\"\n",
    "#     return df.sort_values(by=\"bWendu\")[[\"ymd\", \"bWendu\"]][-topn:]\n",
    "\n",
    "# df.groupby(\"month\").apply(getWenduTopN, topn=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **数据处理流程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #csv\n",
    "# fpath = \"./datas/crazyant/access_pvuv.txt\"\n",
    "# pvuv = pd.read_csv(\n",
    "#     fpath,\n",
    "#     sep=\"\\t\",\n",
    "#     header=None,\n",
    "#     names=['pdate', 'pv', 'uv']\n",
    "# )\n",
    "\n",
    "# #sql\n",
    "# import pymysql\n",
    "# conn = pymysql.connect(\n",
    "#         host='127.0.0.1',\n",
    "#         user='root',\n",
    "#         password='12345678',\n",
    "#         database='test',\n",
    "#         charset='utf8'\n",
    "#     )\n",
    "# mysql_page = pd.read_sql(\"select * from crazyant_pvuv\", con=conn)\n",
    "\n",
    "# #json\n",
    "# with open('finance/finance_company.json', encoding='utf-8') as f:\n",
    "#     df = json.loads(f)\n",
    "    \n",
    "# #pickle\n",
    "# with open('E:\\\\data2.txt','rb') as f:\n",
    "#     df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1 从宏观一点的角度去看数据：查看dataframe的信息\n",
    "# df.info()\n",
    "# #1.1查看每一列的数据类型\n",
    "# df.dtypes\n",
    "# #1.2有多少行，多少列\n",
    "# df.shape\n",
    "\n",
    "# # 2.检查缺失数据\n",
    "# # 如果你要检查每列缺失数据的数量，使用下列代码是最快的方法。\n",
    "# # 可以让你更好地了解哪些列缺失的数据更多，从而确定怎么进行下一步的数据清洗和分析操作。\n",
    "# df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# # 3.是抽出一部分数据来，人工直观地理解数据的意义，尽可能地发现一些问题\n",
    "# df.head()\n",
    "# # 查看这个商品名称的去重项\n",
    "# df['Description'].unique()\n",
    "# np.set_printoptions(threshold=np.inf) # 设置输出全部的内容 threshold就是设置超过了多少条，就会呈现省略 （比如threshold=10的意思是超过10条就会省略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1）调整数据类型\n",
    "* 2）修改列名\n",
    "* 3）选择部分子集\n",
    "* 4）可能存在逻辑问题需要筛选\n",
    "* 5）格式一致化\n",
    "* 6）消灭空值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##调整数据类型\n",
    "# df.dtypes\n",
    "# #字符串转换为数值（整型）\n",
    "# DataDF['Quantity'] = DataDF['Quantity'].astype('int')#float\n",
    "# DataDF.loc[:,'InvoiceDate']=pd.to_datetime(DataDF.loc[:,'InvoiceDate'],\n",
    "#                                            format='%d/%m/%Y', \n",
    "#                                            errors='coerce')\n",
    "# # #format 是你［原始数据］中日期的格式\n",
    "# # %y 两位数的年份表示（00-99）\n",
    "# # %Y 四位数的年份表示（000-9999）\n",
    "# # %m 月份（01-12）\n",
    "# # %d 月内中的一天（0-31）\n",
    "# # %H 24小时制小时数（0-23）\n",
    "# # %I 12小时制小时数（01-12）\n",
    "# # %M 分钟数（00-59）\n",
    "# # %S 秒（00-59）\n",
    "\n",
    "\n",
    "# ##修改列名\n",
    "# #建立字典字典：旧列名和新列名对应关系\n",
    "# colNameDict = {'InvolceDate':'SaleDate','StockCode':'StockNo'} \n",
    "# df.rename(columns = colNameDict,inplace=True)\n",
    "\n",
    "\n",
    "# ##选择部分子集\n",
    "# #选择子集，选择其中一列\n",
    "# subDataDF1=DataDF[\"InvoiceDate\"]\n",
    "# subDataDF1=DataDF[[\"InvoiceDate\",\"UnitPrice\"]]\n",
    "# subDataDF2=DataDF.loc[0:9,:]\n",
    "# #一般来说价格不能为负，所以从逻辑上来说如果价格是小于0的数据应该予以筛出\n",
    "# querySer=DataDF.loc[:,'Quantity']>0\n",
    "# DataDF=DataDF.loc[querySer,:]\n",
    "\n",
    "# ##格式一致化\n",
    "# #1.大小写/去除空格\n",
    "# DataDF['Description']= DataDF['Description'].str.upper()\n",
    "# str().upper() lower() title() lstrip() strip()\n",
    "# #2 去除字符串符号 去乱码\n",
    "# #3. 空格分割\n",
    "# #定义函数：分割InvoiceDate，获取InvoiceDate\n",
    "# #输入：timeColSer InvoiceDate这一列，是个Series数据类型\n",
    "# #输出：分割后的时间，返回也是个Series数据类型\n",
    "# def splitSaletime(timeColSer):\n",
    "#     timeList=[]\n",
    "#     for value in timeColSer:\n",
    "#         #例如2018/01/01 12:50，分割后为：2018-01-01\n",
    "#         dateStr=value.split(' ')[0]\n",
    "#         timeList.append(dateStr)\n",
    "# #将列表转行为一维数据Series类型\n",
    "#     timeSer=pd.Series(timeList)\n",
    "#     return timeSer\n",
    "# DataDF.loc[:,'InvoiceDate']=splitSaletime(DataDF.loc[:,'InvoiceDate'])\n",
    "\n",
    "# ##处理缺失值\n",
    "# #缺失值有3种：None(python)，NA，NaN\n",
    "# DataDF.isnull().sum().sort_values(ascending=False)\n",
    "# #去除\n",
    "# DataDF.dropna(axis=1,how='any')\n",
    "# DataDF.dropna(thresh = 6)\n",
    "# #填补\n",
    "# DataDF.Country.fillna(' ')\n",
    "# df.fillna(df.mean())\n",
    "# DataDF.UnitPrice.fillna(method='ffill')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
